{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration    0: Cost 1.67e-02\n",
      "Iteration 1000: Cost 7.91e-03\n",
      "Iteration 2000: Cost 7.91e-03\n",
      "Iteration 3000: Cost 7.91e-03\n",
      "Iteration 4000: Cost 7.91e-03\n",
      "Iteration 5000: Cost 7.91e-03\n",
      "Iteration 6000: Cost 7.91e-03\n",
      "Iteration 7000: Cost 7.91e-03\n",
      "Iteration 8000: Cost 7.91e-03\n",
      "Iteration 9000: Cost 7.91e-03\n",
      "Optimized parameters (w, b): (  0.4937,   0.1116)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import copy\n",
    "import math\n",
    "\n",
    "# Read dataset\n",
    "dataset = pd.read_csv(\"Housing.csv\")\n",
    "\n",
    "# Extract features and target variable\n",
    "prices = dataset.price.values\n",
    "areas = dataset.area.values\n",
    "\n",
    "# Normalize features and target variable\n",
    "prices_normalized = (prices - np.min(prices)) / (np.max(prices) - np.min(prices))\n",
    "areas_normalized = (areas - np.min(areas)) / (np.max(areas) - np.min(areas))\n",
    "\n",
    "def cost_function(x, y, w, b):\n",
    "    \"\"\"\n",
    "    Calculate the cost function for linear regression.\n",
    "\n",
    "    Args:\n",
    "    x: Feature values\n",
    "    y: Target values\n",
    "    w: Weight parameter\n",
    "    b: Bias parameter\n",
    "\n",
    "    Returns:\n",
    "    float: The cost of the current parameters\n",
    "    \"\"\"\n",
    "    size = len(x)\n",
    "    total = 0\n",
    "    for i in range(size):\n",
    "        y_pred = w * x[i] + b\n",
    "        value_cost = (y_pred - y[i]) ** 2\n",
    "        total += value_cost\n",
    "    total_sum = (1 / (2 * size)) * total\n",
    "    return total_sum\n",
    "\n",
    "def compute_gradient(x, y, w, b):\n",
    "    \"\"\"\n",
    "    Compute the gradient of the cost function with respect to parameters w and b.\n",
    "\n",
    "    Args:\n",
    "    x: Feature values\n",
    "    y: Target values\n",
    "    w: Weight parameter\n",
    "    b: Bias parameter\n",
    "\n",
    "    Returns:\n",
    "    tuple: The gradients with respect to w and b\n",
    "    \"\"\"\n",
    "    m = x.shape[0]    \n",
    "    dj_dw = 0\n",
    "    dj_db = 0\n",
    "    \n",
    "    for i in range(m):  \n",
    "        f_wb = w * x[i] + b \n",
    "        dj_dw_i = (f_wb - y[i]) * x[i] \n",
    "        dj_db_i = f_wb - y[i] \n",
    "        dj_db += dj_db_i\n",
    "        dj_dw += dj_dw_i \n",
    "    dj_dw = dj_dw / m \n",
    "    dj_db = dj_db / m \n",
    "        \n",
    "    return dj_dw, dj_db\n",
    "\n",
    "def gradient_descent(x, y, w_init, b_init, alpha, num_iters, cost_function, gradient_function):\n",
    "    \"\"\"\n",
    "    Perform gradient descent to optimize parameters w and b for linear regression.\n",
    "\n",
    "    Args:\n",
    "    x: Feature values\n",
    "    y: Target values\n",
    "    w_init: Initial value for parameter w\n",
    "    b_init: Initial value for parameter b\n",
    "    alpha: Learning rate\n",
    "    num_iters: Number of iterations\n",
    "    cost_function: Function to calculate the cost\n",
    "    gradient_function: Function to compute the gradient\n",
    "\n",
    "    Returns:\n",
    "    tuple: The optimized parameters w and b, along with lists of cost and parameter history\n",
    "    \"\"\"\n",
    "    w = copy.deepcopy(w_init) \n",
    "    b = copy.deepcopy(b_init)\n",
    "    J_history = []\n",
    "    p_history = []\n",
    "    \n",
    "    for i in range(num_iters):\n",
    "        dj_dw, dj_db = gradient_function(x, y, w, b)     \n",
    "        b = b - alpha * dj_db                            \n",
    "        w = w - alpha * dj_dw                            \n",
    "\n",
    "        if i % math.ceil(num_iters / 10) == 0:\n",
    "            J_history.append(cost_function(x, y, w, b))\n",
    "            p_history.append([w, b])\n",
    "            print(f\"Iteration {i:4}: Cost {J_history[-1]:0.2e}\")\n",
    "\n",
    "    return w, b, J_history, p_history\n",
    "\n",
    "# Initialize parameters\n",
    "initial_w = 0\n",
    "initial_b = 0\n",
    "iterations = 10000\n",
    "learning_rate = .5\n",
    "\n",
    "# Run gradient descent\n",
    "final_w, final_b, cost_history, param_history = gradient_descent(prices_normalized, areas_normalized, \n",
    "                                                                 initial_w, initial_b, learning_rate, \n",
    "                                                                 iterations, cost_function, compute_gradient)\n",
    "\n",
    "# Display final parameters\n",
    "print(f\"Optimized parameters (w, b): ({final_w:8.4f}, {final_b:8.4f})\")\n",
    "\n",
    "# Define a class for linear model\n",
    "class LinearModel:\n",
    "    def __init__(self, w, b):\n",
    "        self.w = w\n",
    "        self.b = b\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.w * x + self.b\n",
    "\n",
    "# Create the linear model instance with final parameters\n",
    "model = LinearModel(w=final_w, b=final_b)\n",
    "\n",
    "# Generate predictions\n",
    "predictions = model.predict(prices_normalized)\n",
    "\n",
    "# Generate different values of w and b\n",
    "w_values = np.linspace(0, model.w, 10)\n",
    "b_values = np.linspace(0, model.b, 10)\n",
    "\n",
    "# Create a function to update the plot for each frame of the animation\n",
    "def update(frame):\n",
    "    plt.cla()  # Clear the current plot\n",
    "    output = w_values[frame] * prices_normalized + b_values[frame]\n",
    "    plt.plot(prices_normalized, output, c='b', label='Regression Line')\n",
    "    plt.scatter(prices_normalized, areas_normalized, marker='x', c='r', label='Actual Values')\n",
    "    plt.xlabel('Price (Normalized)')\n",
    "    plt.ylabel('Area (Normalized)')\n",
    "    plt.title('Effect of Different w and b on Prediction Line')\n",
    "    \n",
    "    # Display the updated values of w and b\n",
    "    plt.text(0.05, 0.95, f'w: {w_values[frame]:.4f}\\nb: {b_values[frame]:.4f}', \n",
    "             horizontalalignment='left', verticalalignment='top', transform=plt.gca().transAxes)\n",
    "    \n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    # Stop the animation when the current w and b values match the final values\n",
    "    if np.allclose(w_values[frame], model.w) and np.allclose(b_values[frame], model.b):\n",
    "        ani.event_source.stop()  # Stop the animation\n",
    "\n",
    "# Create the animation\n",
    "fig = plt.figure(figsize=(10, 6))\n",
    "ani = FuncAnimation(fig, update, frames=len(w_values), interval=50, blit=False)\n",
    "\n",
    "# Display the animation\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R^2 Score: 0.2873\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# Calculate R^2 score\n",
    "r2 = r2_score(areas_normalized, predictions)\n",
    "\n",
    "print(f\"R^2 Score: {r2:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.0907\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Calculate mean absolute error\n",
    "mae = mean_absolute_error(areas_normalized, predictions)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mae:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy Percentage: 69.54%\n"
     ]
    }
   ],
   "source": [
    "threshold = 0.1  # Define threshold\n",
    "\n",
    "# Count number of correct predictions within threshold\n",
    "num_correct = np.sum(np.abs(predictions - areas_normalized) <= threshold)\n",
    "\n",
    "# Calculate accuracy percentage\n",
    "accuracy_percent = (num_correct / len(predictions)) * 100\n",
    "\n",
    "print(f\"Accuracy Percentage: {accuracy_percent:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
